{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text\n",
    "file_object  = open(\"texto.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the cropus into sentences\n",
    "lines = []\n",
    "for i in file_object:\n",
    "    l = ''\n",
    "    line = i.split()[4:]\n",
    "    for j in line:\n",
    "        l += j + \" \"\n",
    "    lines.append(l)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the training corpus\n",
    "corpus  = open(\"us-b-1.txt\", \"r\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tagged word from corpus\n",
    "tagged_corpus = []\n",
    "for i in corpus: \n",
    "    line = i.split()\n",
    "    if len(line) > 4:\n",
    "        token = line[2]\n",
    "        tag = line[4]\n",
    "        tagged_corpus.append((token,tag))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sentences from the already tagged corpus\n",
    "count = 0 \n",
    "length = len(tagged_corpus)\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "while count < length:\n",
    "    word = tagged_corpus[count]\n",
    "    if word != ('@','n'):\n",
    "        sentence.append(word)\n",
    "    else:\n",
    "        tagged_sentences.append(sentence)\n",
    "        sentence = []\n",
    "        count += 10\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a tagger\n",
    "unigram_tagger = nltk.UnigramTagger(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tags to more readeable ones\n",
    "def retag(word):\n",
    "    word = list(word)\n",
    "    token = word[0] \n",
    "    tag = word[1]  \n",
    "    if tag == None:\n",
    "        tag = '*****'\n",
    "    if 'n' in tag and 'v' not in tag:\n",
    "        tag = \"NOUN\"\n",
    "    if 'm' in tag and 'n' not in tag:\n",
    "        tag = 'NUM'\n",
    "    if 'dx' in tag:\n",
    "        tag = 'DET'\n",
    "    if 'v' in tag:\n",
    "        tag = 'VERB'\n",
    "    if 'c' in tag:\n",
    "        tag = \"CONJ\"\n",
    "    if 'o' == tag:\n",
    "        tag = \"PROP_NOUN\"\n",
    "    if 'd' in tag:\n",
    "        tag = \"DET\"\n",
    "    if 'j' in tag:\n",
    "        tag = \"ADJ\"\n",
    "    if 'r' == tag:\n",
    "        tag = \"ADJ\"\n",
    "    if 'po' == tag:\n",
    "        tag = \"PRON\"\n",
    "    if 'f' in tag:\n",
    "        tag = 'FOREIGN'\n",
    "    if 'y' in tag:\n",
    "        tag = \"PUNCT\"\n",
    "    if 'e' in tag:\n",
    "        tag = \"PREP\"\n",
    "    if 'i' == tag:\n",
    "        tag = \"INTJ\"\n",
    "    \n",
    "    return ((token,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag new data\n",
    "final_tagged_corpus = [[('word','spanish_tag','english_tag')]]\n",
    "for word in lines:\n",
    "    tokens = nltk.word_tokenize(word)\n",
    "    SPN_tag_pre = unigram_tagger.tag(tokens)\n",
    "    ENG_TAG = nltk.pos_tag(tokens)\n",
    "    SPN_TAG = []\n",
    "    sentence = []\n",
    "    if len(SPN_tag) > 1:  \n",
    "        for token in SPN_tag_pre:\n",
    "            SPN_TAG.append(retag(token))\n",
    "        for i in range(len(SPN_TAG)): \n",
    "            spn = list(SPN_TAG[i])\n",
    "            word = spn[0]\n",
    "            spn_tag = spn[1]\n",
    "            eng_tag = list(ENG_TAG[i])[1]\n",
    "            sentence.append((word,spn_tag,eng_tag))\n",
    "        final_tagged_corpus.append(sentence)\n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tagged_data.txt', 'w') as f:\n",
    "    n = 1\n",
    "    for sentence in final_tagged_corpus:\n",
    "        if len(sentence) > 0:\n",
    "            for word in sentence:\n",
    "                for j in word:\n",
    "                    f.write(j+\"\\t\")\n",
    "                f.write('\\n')\n",
    "            f.write('New\\t')\n",
    "            f.write('Sentence\\t')\n",
    "            f.write(str(n)+\"\\t\")\n",
    "            f.write('\\n')\n",
    "            n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
